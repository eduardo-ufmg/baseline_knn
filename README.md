# Baseline KNN Classifier

A comprehensive k-Nearest Neighbors (k-NN) classifier implementation with automated hyperparameter tuning using Bayesian Optimization. This project serves as a baseline for comparing different k-NN variants and implementations.

## ğŸš€ Features

- **Automated Hyperparameter Tuning**: Uses Bayesian Optimization via `scikit-optimize` to find optimal parameters
- **Comprehensive Evaluation**: Cross-validation experiments with detailed performance metrics
- **Dataset Management**: Tools for downloading, preprocessing, and validating datasets from multiple sources
- **Memory and Time Profiling**: Tracks both CPU time and memory usage during training and prediction
- **Parallel Processing**: Efficient parallel execution for large-scale experiments
- **sklearn Compatible**: Follows sklearn's BaseEstimator and ClassifierMixin interfaces

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- pip or conda

### Install Dependencies

```bash
pip install -e .
```

For development dependencies:
```bash
pip install -e ".[dev]"
```

## ğŸ”§ Usage

### Basic Usage

```python
from classifier.knn import BaselineKNNClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load sample data
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Create and train the classifier
clf = BaselineKNNClassifier(n_iter=32, cv=5, random_state=0)
clf.fit(X_train, y_train)

# Make predictions
predictions = clf.predict(X_test)
probabilities = clf.predict_proba(X_test)

# Access the best parameters found
print(f"Best parameters: {clf.best_params_}")
print(f"Best CV score: {clf.best_score_}")
```

### Running Experiments

The project includes a comprehensive experiment runner that evaluates the classifier on multiple datasets:

```bash
# Download and preprocess datasets
python store_datasets/store_sets.py ./datasets

# Run cross-validation experiments
python experiment.py ./datasets ./results/experiment_results.csv
```

### Dataset Management

The `store_datasets` module provides tools for managing datasets from various sources:

```python
# Download datasets from sklearn, OpenML, and UCI repositories
python store_datasets/store_sets.py ./my_datasets

# Validate processed datasets
python store_datasets/test.py ./my_datasets
```

## ğŸ—ï¸ Project Structure

```
baseline_knn/
â”œâ”€â”€ classifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ knn.py              # Main BaselineKNNClassifier implementation
â”œâ”€â”€ store_datasets/         # Dataset management tools (git submodule)
â”‚   â”œâ”€â”€ store_sets.py       # Download and preprocess datasets
â”‚   â”œâ”€â”€ test.py            # Validate datasets
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py        # Test fixtures and configuration
â”‚   â””â”€â”€ test_knn.py        # Comprehensive test suite
â”œâ”€â”€ results/               # Experiment results
â”œâ”€â”€ sets/                  # Dataset storage
â”œâ”€â”€ experiment.py          # Main experiment runner
â”œâ”€â”€ pyproject.toml         # Project configuration
â””â”€â”€ README.md
```

## ğŸ§ª BaselineKNNClassifier

The core classifier automatically optimizes the following hyperparameters:

- **n_neighbors**: Number of neighbors (1 to min(50, safe_max))
- **weights**: Weighting scheme ('uniform' or 'distance')
- **p**: Distance metric (1 for Manhattan, 2 for Euclidean)

### Parameters

- `n_iter` (int, default=8): Number of optimization iterations
- `cv` (int, default=3): Number of cross-validation folds
- `random_state` (int, default=0): Random seed for reproducibility

### Attributes (after fitting)

- `best_estimator_`: The best KNeighborsClassifier found
- `best_params_`: Dictionary of best hyperparameters
- `best_score_`: Best cross-validation score achieved
- `classes_`: Array of class labels

## ğŸ“Š Experiment Results

The experiment runner provides detailed metrics:

- **Accuracy**: Mean and standard deviation across CV folds
- **Timing**: CPU time for fitting and prediction
- **Memory**: Peak memory usage during training and inference
- **Preprocessing**: Automatic feature scaling, variance filtering, and PCA

Results are saved in CSV format with columns:
- `dataset`: Dataset name
- `accuracy_mean/std`: Classification accuracy statistics
- `fit_time_cpu_mean/std`: Training time statistics
- `predict_time_cpu_mean/std`: Prediction time statistics
- `fit_mem_peak_mean_mb/std_mb`: Memory usage statistics
- `predict_mem_peak_mean_mb/std_mb`: Prediction memory statistics

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=classifier

# Run specific test file
pytest tests/test_knn.py
```

### Test Coverage

The test suite includes:
- Parameter validation and edge cases
- Fit/predict functionality
- Input validation and error handling
- Reproducibility tests
- Performance benchmarks
- sklearn compatibility checks

## ğŸ› ï¸ Development

### Code Quality

This project uses several tools to maintain code quality:

```bash
# Format code
black .

# Sort imports
isort .

# Lint code
flake8 .

# Type checking
mypy .

# Security scanning
bandit -c pyproject.toml -r .
```

### Pre-commit Hooks

Install pre-commit hooks to automatically run quality checks:

```bash
pre-commit install
```

## ğŸ“ˆ Performance Characteristics

- **Time Complexity**: O(n_iter Ã— cv Ã— n_samples Ã— n_features) for training
- **Space Complexity**: O(n_samples Ã— n_features) for storage
- **Scalability**: Efficient parallel processing for multiple datasets
- **Memory Profiling**: Tracks peak memory usage during operations

## ğŸ” Dataset Sources

The project supports datasets from:
- **sklearn**: Built-in datasets (iris, wine, breast_cancer, etc.)
- **OpenML**: Community machine learning datasets
- **UCI**: University of California Irvine ML repository

All datasets are automatically:
- Cleaned and preprocessed
- Split into features and targets
- Validated for quality
- Stored in standardized CSV format

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Clone the repository
git clone https://github.com/your-username/baseline_knn.git
cd baseline_knn

# Install in development mode
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

**Eduardo Henrique Basilio de Carvalho**
- Email: eduardohbc@ufmg.com
- University: UFMG (Universidade Federal de Minas Gerais)

## ğŸ™ Acknowledgments

- [scikit-learn](https://scikit-learn.org/) for the base k-NN implementation
- [scikit-optimize](https://scikit-optimize.github.io/) for Bayesian optimization
- [OpenML](https://www.openml.org/) and [UCI ML Repository](https://archive.ics.uci.edu/ml/) for datasets

## ğŸ“š Citation

If you use this baseline in your research, please cite:

```bibtex
@software{baseline_knn,
  author = {Eduardo Henrique Basilio de Carvalho},
  title = {Baseline KNN Classifier},
  url = {https://github.com/your-username/baseline_knn},
  version = {0.1.0},
  year = {2025}
}
```
